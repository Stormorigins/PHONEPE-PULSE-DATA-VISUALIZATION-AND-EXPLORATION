{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "112a9ebc",
   "metadata": {},
   "source": [
    "LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "808ba386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0cce1a",
   "metadata": {},
   "source": [
    "DATA EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adfbb5e",
   "metadata": {},
   "source": [
    "AGGREGATED DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f2508",
   "metadata": {},
   "source": [
    "TRANSACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c45dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggre TX\n",
    "\n",
    "Aggre_path1= \"C:/Users/Aishwarya MMPL/Documents/GUVI_PYTHON/Projects/phonepe/pulse/data/aggregated/transaction/country/india/state/\"\n",
    "Agg_tx= os.listdir(Aggre_path1)\n",
    "\n",
    "\n",
    "Tx_col1={\"States\": [], \"Years\": [], \"Quaters\": [], \"Transaction_type\": [], \"Transaction_count\": [],\"Transaction_amount\": []}\n",
    "\n",
    "#get  path access untill states \n",
    "\n",
    "for state1 in Agg_tx:\n",
    "    currentstate = Aggre_path1+state1+\"/\"\n",
    "    aggre_year=os.listdir(currentstate)\n",
    "    \n",
    "#get  path access each years of states \n",
    "    \n",
    "    for year1 in aggre_year:\n",
    "        currentyear=currentstate+year1+\"/\"\n",
    "        aggre_file=os.listdir(currentyear)\n",
    "        \n",
    "#get  path access each file and load every file  \n",
    "\n",
    "        for file1 in aggre_file:\n",
    "            currentfile=currentyear+file1\n",
    "            data = open(currentfile,\"r\")\n",
    "            \n",
    "            A1=json.load(data)\n",
    "            for i in A1[\"data\"][\"transactionData\"]:\n",
    "                data = i[\"name\"]\n",
    "                Tx_col1[\"Transaction_type\"].append(data)\n",
    "                data2 = i[\"paymentInstruments\"][0][\"count\"]\n",
    "                Tx_col1[\"Transaction_count\"].append(data2)\n",
    "                data3 = i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                Tx_col1[\"Transaction_amount\"].append(data3)\n",
    "                Tx_col1[\"States\"].append(state1)\n",
    "                Tx_col1[\"Years\"].append(year1)\n",
    "                Tx_col1[\"Quaters\"].append(int(file1.strip(\".json\")))\n",
    "                \n",
    "Agg_tx_df = pd.DataFrame(Tx_col1)\n",
    "\n",
    "Agg_tx_df[\"States\"]=Agg_tx_df[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Agg_tx_df[\"States\"]=Agg_tx_df[\"States\"].str.replace(\"-\",\" \")\n",
    "Agg_tx_df[\"States\"]=Agg_tx_df[\"States\"].str.title()\n",
    "Agg_tx_df[\"States\"]=Agg_tx_df[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ad5da",
   "metadata": {},
   "source": [
    "USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fbeb943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggre User\n",
    "\n",
    "Aggre_path2= \"C:/Users/Aishwarya MMPL/Documents/GUVI_PYTHON/Projects/phonepe/pulse/data/aggregated/user/country/india/state/\"\n",
    "Agg_Us= os.listdir(Aggre_path2)\n",
    "\n",
    "Tx_col2={\"States\": [], \"Years\": [], \"Quaters\": [], \"Brands\": [], \"Transaction_count\": [],\"Percentage\": []}\n",
    "\n",
    "\n",
    "#get  path access untill states \n",
    "\n",
    "for state2 in Agg_Us:\n",
    "    currentstate2 = Aggre_path2+state2+\"/\"\n",
    "    aggre_year2=os.listdir(currentstate2)\n",
    "    \n",
    "#get  path access each years of states \n",
    "    \n",
    "    for year2 in aggre_year2:\n",
    "        currentyear2=currentstate2+year2+\"/\"\n",
    "        aggre_file2=os.listdir(currentyear2)\n",
    "        \n",
    "\n",
    "#get  path access each file and load every file \n",
    "        \n",
    "        for file2 in aggre_file2:\n",
    "            currentfile2=currentyear2+file2\n",
    "            data2 = open(currentfile2,\"r\")\n",
    "            \n",
    "            A2=json.load(data2)\n",
    "\n",
    "#use try & except to pass type error\n",
    "\n",
    "            try:\n",
    "                \n",
    "                for i in A2[\"data\"][\"usersByDevice\"]:\n",
    "                    data = i[\"brand\"]\n",
    "                    Tx_col2[\"Brands\"].append(data)\n",
    "                    data2 = i[\"count\"]\n",
    "                    Tx_col2[\"Transaction_count\"].append(data2)\n",
    "                    data3 = i[\"percentage\"]\n",
    "                    Tx_col2[\"Percentage\"].append(data3)\n",
    "                    Tx_col2[\"States\"].append(state2)\n",
    "                    Tx_col2[\"Years\"].append(year2)\n",
    "                    Tx_col2[\"Quaters\"].append(int(file2.strip(\".json\")))\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "Agg_User_df = pd.DataFrame(Tx_col2)\n",
    "\n",
    "Agg_User_df[\"States\"]=Agg_User_df[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Agg_User_df[\"States\"]=Agg_User_df[\"States\"].str.replace(\"-\",\" \")\n",
    "Agg_User_df[\"States\"]=Agg_User_df[\"States\"].str.title()\n",
    "Agg_User_df[\"States\"]=Agg_User_df[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3a29c7",
   "metadata": {},
   "source": [
    "INSURANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7e218c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggre insurance\n",
    "\n",
    "Aggre_path3= \"C:/Users/Aishwarya MMPL/Documents/GUVI_PYTHON/Projects/phonepe/pulse/data/aggregated/insurance/country/india/state/\"\n",
    "Agg_ins= os.listdir(Aggre_path3)\n",
    "\n",
    "\n",
    "Tx_col3={\"States\": [], \"Years\": [], \"Quaters\": [], \"Transaction_Type\": [], \"Transaction_count\": [],\"Transaction_amount\": []}\n",
    "\n",
    "#get  path access untill states \n",
    "\n",
    "for state3 in Agg_ins:\n",
    "    currentstate3 = Aggre_path3+state3+\"/\"\n",
    "    aggre_year3=os.listdir(currentstate3)\n",
    "    \n",
    "#get  path access each years of states \n",
    "    \n",
    "    for year3 in aggre_year3:\n",
    "        currentyear3=currentstate3+year3+\"/\"\n",
    "        aggre_file3=os.listdir(currentyear3)\n",
    "        \n",
    "#get  path access each file and load every file  \n",
    "\n",
    "        for file3 in aggre_file3:\n",
    "            currentfile3=currentyear3+file3\n",
    "            data3 = open(currentfile3,\"r\")\n",
    "            \n",
    "            A3=json.load(data3)\n",
    "            for i in A3[\"data\"][\"transactionData\"]:\n",
    "                    data= i[\"paymentInstruments\"][0][\"count\"]\n",
    "                    Tx_col3[\"Transaction_count\"].append(data)\n",
    "                    data2 = i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                    Tx_col3[\"Transaction_amount\"].append(data2)\n",
    "                    data3 = i[\"name\"]\n",
    "                    Tx_col3[\"Transaction_Type\"].append(data3)\n",
    "                    Tx_col3[\"States\"].append(state3)\n",
    "                    Tx_col3[\"Years\"].append(year3)\n",
    "                    Tx_col3[\"Quaters\"].append(int(file3.strip(\".json\")))\n",
    "                    \n",
    "Agg_Ins_df = pd.DataFrame(Tx_col3)\n",
    "\n",
    "Agg_Ins_df[\"States\"]=Agg_Ins_df[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Agg_Ins_df[\"States\"]=Agg_Ins_df[\"States\"].str.replace(\"-\",\" \")\n",
    "Agg_Ins_df[\"States\"]=Agg_Ins_df[\"States\"].str.title()\n",
    "Agg_Ins_df[\"States\"]=Agg_Ins_df[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d4234",
   "metadata": {},
   "source": [
    "MAP DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895756fd",
   "metadata": {},
   "source": [
    "TRANSACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f186a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map TX\n",
    "\n",
    "Map_path1= \"C:/Users/Aishwarya MMPL/Documents/GUVI_PYTHON/Projects/phonepe/pulse/data/map/transaction/hover/country/india/state/\"\n",
    "Map_tx= os.listdir(Map_path1)\n",
    "\n",
    "\n",
    "Map_col1={\"States\": [], \"Years\": [], \"Quaters\": [], \"Districts\": [], \"Transaction_count\": [],\"Transaction_amount\": []}\n",
    "\n",
    "#get  path access untill states \n",
    "\n",
    "for state1 in Map_tx:\n",
    "    currentstate = Map_path1+state1+\"/\"\n",
    "    Map_year=os.listdir(currentstate)\n",
    "    \n",
    "#get  path access each years of states \n",
    "    \n",
    "    for year1 in Map_year:\n",
    "        currentyear=currentstate+year1+\"/\"\n",
    "        Map_file=os.listdir(currentyear)\n",
    "        \n",
    "#get  path access each file and load every file  \n",
    "\n",
    "        for file1 in Map_file:\n",
    "            currentfile=currentyear+file1\n",
    "            data = open(currentfile,\"r\")\n",
    "            \n",
    "            B1=json.load(data)\n",
    "           \n",
    "            \n",
    "            for i in B1[\"data\"][\"hoverDataList\"]:\n",
    "                data = i[\"name\"]\n",
    "                Map_col1[\"Districts\"].append(data)\n",
    "                data2 = i[\"metric\"][0][\"count\"]\n",
    "                Map_col1[\"Transaction_count\"].append(data2)\n",
    "                data3 = i[\"metric\"][0][\"amount\"]\n",
    "                Map_col1[\"Transaction_amount\"].append(data3)\n",
    "                Map_col1[\"States\"].append(state1)\n",
    "                Map_col1[\"Years\"].append(year1)\n",
    "                Map_col1[\"Quaters\"].append(int(file1.strip(\".json\")))\n",
    "                \n",
    "Map_Tx_df = pd.DataFrame(Map_col1)\n",
    "\n",
    "Map_Tx_df[\"States\"]=Map_Tx_df[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Map_Tx_df[\"States\"]=Map_Tx_df[\"States\"].str.replace(\"-\",\" \")\n",
    "Map_Tx_df[\"States\"]=Map_Tx_df[\"States\"].str.title()\n",
    "Map_Tx_df[\"States\"]=Map_Tx_df[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a29b09",
   "metadata": {},
   "source": [
    "USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68bfdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map User\n",
    "\n",
    "Map_path2= \"C:/Users/Aishwarya MMPL/Documents/GUVI_PYTHON/Projects/phonepe/pulse/data/map/user/hover/country/india/state/\"\n",
    "Map_Us= os.listdir(Map_path2)\n",
    "\n",
    "Map_col2={\"States\": [], \"Years\": [], \"Quaters\": [], \"Districts\": [], \"Registered_Users\": [],\"App_Opens\": []}\n",
    "\n",
    "\n",
    "#get  path access untill states \n",
    "\n",
    "for state2 in Map_Us:\n",
    "    currentstate2 = Map_path2+state2+\"/\"\n",
    "    aggre_year2=os.listdir(currentstate2)\n",
    "    \n",
    "#get  path access each years of states \n",
    "    \n",
    "    for year2 in aggre_year2:\n",
    "        currentyear2=currentstate2+year2+\"/\"\n",
    "        aggre_file2=os.listdir(currentyear2)\n",
    "        \n",
    "\n",
    "#get  path access each file and load every file \n",
    "        \n",
    "        for file2 in aggre_file2:\n",
    "            currentfile2=currentyear2+file2\n",
    "            data2 = open(currentfile2,\"r\")\n",
    "            \n",
    "            B2=json.load(data2)\n",
    "            \n",
    "            for i in B2[\"data\"][\"hoverData\"].items():\n",
    "                data= i[0]\n",
    "                Map_col2[\"Districts\"].append(data)\n",
    "                data2 = i[1][\"registeredUsers\"]\n",
    "                Map_col2[\"Registered_Users\"].append(data2)\n",
    "                data3 = i[1][\"appOpens\"]\n",
    "                Map_col2[\"App_Opens\"].append(data3)\n",
    "                Map_col2[\"States\"].append(state2)\n",
    "                Map_col2[\"Years\"].append(year2)\n",
    "                Map_col2[\"Quaters\"].append(int(file2.strip(\".json\")))\n",
    "                \n",
    "Map_Us_df = pd.DataFrame(Map_col2)\n",
    "\n",
    "Map_Us_df[\"States\"]=Map_Us_df[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Map_Us_df[\"States\"]=Map_Us_df[\"States\"].str.replace(\"-\",\" \")\n",
    "Map_Us_df[\"States\"]=Map_Us_df[\"States\"].str.title()\n",
    "Map_Us_df[\"States\"]=Map_Us_df[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ab7e4",
   "metadata": {},
   "source": [
    "INSURANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3c3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map insurance\n",
    "\n",
    "Map_path3= \"C:/Users/Aishwarya MMPL/Documents/GUVI_PYTHON/Projects/phonepe/pulse/data/map/insurance/hover/country/india/state/\"\n",
    "Map_ins= os.listdir(Map_path3)\n",
    "\n",
    "\n",
    "Map_col3={\"States\": [], \"Years\": [], \"Quaters\": [], \"Districts\": [], \"Transaction_count\": [],\"Transaction_amount\": []}\n",
    "\n",
    "#get  path access untill states \n",
    "\n",
    "for state3 in Map_ins:\n",
    "    currentstate3 = Map_path3+state3+\"/\"\n",
    "    aggre_year3=os.listdir(currentstate3)\n",
    "    \n",
    "#get  path access each years of states \n",
    "    \n",
    "    for year3 in aggre_year3:\n",
    "        currentyear3=currentstate3+year3+\"/\"\n",
    "        aggre_file3=os.listdir(currentyear3)\n",
    "        \n",
    "#get  path access each file and load every file  \n",
    "\n",
    "        for file3 in aggre_file3:\n",
    "            currentfile3=currentyear3+file3\n",
    "            data3 = open(currentfile3,\"r\")\n",
    "            \n",
    "            B3=json.load(data3)\n",
    "            \n",
    "            for i in B3[\"data\"][\"hoverDataList\"]:\n",
    "                data =i[\"name\"]\n",
    "                Map_col3[\"Districts\"].append(data)\n",
    "                data2= i[\"metric\"][0][\"count\"]\n",
    "                Map_col3[\"Transaction_count\"].append(data2)\n",
    "                data3 = i[\"metric\"][0][\"amount\"]\n",
    "                Map_col3[\"Transaction_amount\"].append(data3)\n",
    "                Map_col3[\"States\"].append(state3)\n",
    "                Map_col3[\"Years\"].append(year3)\n",
    "                Map_col3[\"Quaters\"].append(int(file3.strip(\".json\")))\n",
    "                \n",
    "Map_ins_df = pd.DataFrame(Map_col3)\n",
    "\n",
    "Map_ins_df[\"States\"]=Map_ins_df[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Map_ins_df[\"States\"]=Map_ins_df[\"States\"].str.replace(\"-\",\" \")\n",
    "Map_ins_df[\"States\"]=Map_ins_df[\"States\"].str.title()\n",
    "Map_ins_df[\"States\"]=Map_ins_df[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "          \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1dbaba",
   "metadata": {},
   "source": [
    "TOP DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fba1e6",
   "metadata": {},
   "source": [
    "TRANSACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b89ea459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top TX\n",
    "\n",
    "Top_path1= \"C:/Users/Aishwarya MMPL/Documents/GUVI_PYTHON/Projects/phonepe/pulse/data/top/transaction/country/india/state/\"\n",
    "Top_tx= os.listdir(Top_path1)\n",
    "\n",
    "\n",
    "Top_col1={\"States\": [], \"Years\": [], \"Quaters\": [], \"Pincodes\": [], \"Transaction_count\": [],\"Transaction_amount\": []}\n",
    "\n",
    "#get  path access untill states \n",
    "\n",
    "for state1 in Top_tx:\n",
    "    currentstate = Top_path1+state1+\"/\"\n",
    "    Map_year=os.listdir(currentstate)\n",
    "    \n",
    "#get  path access each years of states \n",
    "    \n",
    "    for year1 in Map_year:\n",
    "        currentyear=currentstate+year1+\"/\"\n",
    "        Map_file=os.listdir(currentyear)\n",
    "        \n",
    "#get  path access each file and load every file  \n",
    "\n",
    "        for file1 in Map_file:\n",
    "            currentfile=currentyear+file1\n",
    "            data = open(currentfile,\"r\")\n",
    "            \n",
    "            C1=json.load(data)\n",
    "           \n",
    "            for i in C1[\"data\"][\"pincodes\"]:\n",
    "                data =i[\"entityName\"]\n",
    "                Top_col1[\"Pincodes\"].append(data)\n",
    "                data2= i[\"metric\"][\"count\"]\n",
    "                Top_col1[\"Transaction_count\"].append(data2)\n",
    "                data3 = i[\"metric\"][\"amount\"]\n",
    "                Top_col1[\"Transaction_amount\"].append(data3)\n",
    "                Top_col1[\"States\"].append(state1)\n",
    "                Top_col1[\"Years\"].append(year1)\n",
    "                Top_col1[\"Quaters\"].append(int(file1.strip(\".json\")))\n",
    "                \n",
    "Top_Tx_df = pd.DataFrame(Top_col1)\n",
    "\n",
    "Top_Tx_df[\"States\"]=Top_Tx_df[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Top_Tx_df[\"States\"]=Top_Tx_df[\"States\"].str.replace(\"-\",\" \")\n",
    "Top_Tx_df[\"States\"]=Top_Tx_df[\"States\"].str.title()\n",
    "Top_Tx_df[\"States\"]=Top_Tx_df[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc4735",
   "metadata": {},
   "source": [
    "USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adb2b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top User\n",
    "\n",
    "Top_path2= \"C:/Users/Aishwarya MMPL/Documents/GUVI_PYTHON/Projects/phonepe/pulse/data/top/user/country/india/state/\"\n",
    "Top_Us= os.listdir(Top_path2)\n",
    "\n",
    "Top_col2={\"States\": [], \"Years\": [], \"Quaters\": [], \"Pincodes\": [], \"Registered_Users\": []}\n",
    "\n",
    "\n",
    "#get  path access untill states \n",
    "\n",
    "for state2 in Top_Us:\n",
    "    currentstate2 = Top_path2+state2+\"/\"\n",
    "    aggre_year2=os.listdir(currentstate2)\n",
    "    \n",
    "#get  path access each years of states \n",
    "    \n",
    "    for year2 in aggre_year2:\n",
    "        currentyear2=currentstate2+year2+\"/\"\n",
    "        aggre_file2=os.listdir(currentyear2)\n",
    "        \n",
    "\n",
    "#get  path access each file and load every file \n",
    "        \n",
    "        for file2 in aggre_file2:\n",
    "            currentfile2=currentyear2+file2\n",
    "            data2 = open(currentfile2,\"r\")\n",
    "            \n",
    "            C2=json.load(data2)\n",
    "            \n",
    "            for i in C2[\"data\"][\"pincodes\"]:\n",
    "                data= i[\"name\"]\n",
    "                Top_col2[\"Pincodes\"].append(data)\n",
    "                data2 = i[\"registeredUsers\"]\n",
    "                Top_col2[\"Registered_Users\"].append(data2)\n",
    "                Top_col2[\"States\"].append(state2)\n",
    "                Top_col2[\"Years\"].append(year2)\n",
    "                Top_col2[\"Quaters\"].append(int(file2.strip(\".json\")))\n",
    "                \n",
    "Top_Us_df = pd.DataFrame(Top_col2)\n",
    "                \n",
    "Top_Us_df[\"States\"]=Top_Us_df[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Top_Us_df[\"States\"]=Top_Us_df[\"States\"].str.replace(\"-\",\" \")\n",
    "Top_Us_df[\"States\"]=Top_Us_df[\"States\"].str.title()\n",
    "Top_Us_df[\"States\"]=Top_Us_df[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990955bb",
   "metadata": {},
   "source": [
    "INSURANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2461bf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top insurance\n",
    "\n",
    "Top_path3= \"C:/Users/Aishwarya MMPL/Documents/GUVI_PYTHON/Projects/phonepe/pulse/data/top/insurance/country/india/state/\"\n",
    "Top_ins= os.listdir(Top_path3)\n",
    "\n",
    "\n",
    "Top_col3={\"States\": [], \"Years\": [], \"Quaters\": [], \"Pincodes\": [], \"Transaction_count\": [],\"Transaction_amount\": []}\n",
    "\n",
    "#get  path access untill states \n",
    "\n",
    "for state3 in Top_ins:\n",
    "    currentstate3 = Top_path3+state3+\"/\"\n",
    "    aggre_year3=os.listdir(currentstate3)\n",
    "    \n",
    "#get  path access each years of states \n",
    "    \n",
    "    for year3 in aggre_year3:\n",
    "        currentyear3=currentstate3+year3+\"/\"\n",
    "        aggre_file3=os.listdir(currentyear3)\n",
    "        \n",
    "#get  path access each file and load every file  \n",
    "\n",
    "        for file3 in aggre_file3:\n",
    "            currentfile3=currentyear3+file3\n",
    "            data3 = open(currentfile3,\"r\")\n",
    "            \n",
    "            C3=json.load(data3)\n",
    "            \n",
    "            for i in C3[\"data\"][\"pincodes\"]:\n",
    "                data =i[\"entityName\"]\n",
    "                Top_col3[\"Pincodes\"].append(data)\n",
    "                data2= i[\"metric\"][\"count\"]\n",
    "                Top_col3[\"Transaction_count\"].append(data2)\n",
    "                data3 = i[\"metric\"][\"amount\"]\n",
    "                Top_col3[\"Transaction_amount\"].append(data3)\n",
    "                Top_col3[\"States\"].append(state3)\n",
    "                Top_col3[\"Years\"].append(year3)\n",
    "                Top_col3[\"Quaters\"].append(int(file3.strip(\".json\")))\n",
    "                \n",
    "Top_ins_df = pd.DataFrame(Top_col3)\n",
    "\n",
    "Top_ins_df[\"States\"]=Top_ins_df[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Top_ins_df[\"States\"]=Top_ins_df[\"States\"].str.replace(\"-\",\" \")\n",
    "Top_ins_df[\"States\"]=Top_ins_df[\"States\"].str.title()\n",
    "Top_ins_df[\"States\"]=Top_ins_df[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee912fb",
   "metadata": {},
   "source": [
    "TABLE CREATION FOR AGGREGATED DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac444b8",
   "metadata": {},
   "source": [
    "CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "025bf079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql connection\n",
    "myconnection = pymysql.connect(host = '127.0.0.1',user='root',passwd='root',database = \"phonepe\",port=3306)\n",
    "cur = myconnection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fca6ac",
   "metadata": {},
   "source": [
    "TRANSACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa0b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql connection\n",
    "myconnection = pymysql.connect(host = '127.0.0.1',user='root',passwd='root',database = \"phonepe\",port=3306)\n",
    "cur = myconnection.cursor()\n",
    "\n",
    "#Agg_trans_query\n",
    "drop_Table='''drop table if exists Agg_Tx'''\n",
    "cur.execute(drop_Table)\n",
    "myconnection.commit()\n",
    "\n",
    "Create_QueryA1='''create table if not exists Agg_Tx(States char(255),Years int, Quaters int, Transaction_type char(255),\n",
    "                                            Transaction_count bigint, Transaction_amount bigint)'''\n",
    "cur.execute(Create_QueryA1)\n",
    "myconnection.commit()\n",
    "\n",
    "Insert_QueryA1='''insert into Agg_Tx(States, Years, Quaters, Transaction_type, Transaction_count, Transaction_amount)\n",
    "                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "Agg_Tx_datas= Agg_tx_df.values.tolist()\n",
    "\n",
    "cur.executemany(Insert_QueryA1,Agg_Tx_datas)\n",
    "myconnection.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935a4db",
   "metadata": {},
   "source": [
    "USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b5a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql connection\n",
    "myconnection = pymysql.connect(host = '127.0.0.1',user='root',passwd='root',database = \"phonepe\",port=3306)\n",
    "cur = myconnection.cursor()\n",
    "\n",
    "#Agg_User_query\n",
    "drop_Table='''drop table if exists Agg_Us'''\n",
    "cur.execute(drop_Table)\n",
    "myconnection.commit()\n",
    "\n",
    "Create_QueryA2='''create table if not exists Agg_Us(States char(255),Years int, Quaters int, Brands char(255),\n",
    "                                            Transaction_count bigint, Percentage float)'''\n",
    "cur.execute(Create_QueryA2)\n",
    "myconnection.commit()\n",
    "\n",
    "Insert_QueryA2='''insert into Agg_Us(States, Years, Quaters, Brands, Transaction_count, Percentage)\n",
    "                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "Agg_Us_datas= Agg_User_df.values.tolist()\n",
    "\n",
    "cur.executemany(Insert_QueryA2,Agg_Us_datas)\n",
    "myconnection.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e28f878",
   "metadata": {},
   "source": [
    "INSURANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "myconnection = pymysql.connect(host = '127.0.0.1',user='root',passwd='root',database = \"phonepe\",port=3306)\n",
    "cur = myconnection.cursor()\n",
    "\n",
    "#Agg_Ins_query\n",
    "drop_Table='''drop table if exists Agg_Ins'''\n",
    "cur.execute(drop_Table)\n",
    "myconnection.commit()\n",
    "\n",
    "\n",
    "Create_QueryA3='''create table if not exists Agg_Ins(States char(255),Years int, Quaters int, Transaction_type char(255),\n",
    "                                            Transaction_count bigint, Transaction_amount bigint)'''\n",
    "cur.execute(Create_QueryA3)\n",
    "myconnection.commit()\n",
    "\n",
    "Insert_QueryA3='''insert into Agg_Ins(States, Years, Quaters, Transaction_type, Transaction_count, Transaction_amount)\n",
    "                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "Agg_Ins_datas= Agg_Ins_df.values.tolist()\n",
    "\n",
    "cur.executemany(Insert_QueryA3,Agg_Ins_datas)\n",
    "myconnection.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a893305c",
   "metadata": {},
   "source": [
    "TABLE CREATION FOR MAP DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34916063",
   "metadata": {},
   "source": [
    "TRANSACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql connection\n",
    "myconnection = pymysql.connect(host = '127.0.0.1',user='root',passwd='root',database = \"phonepe\",port=3306)\n",
    "cur = myconnection.cursor()\n",
    "\n",
    "#Map_trans_query\n",
    "drop_Table='''drop table if exists Map_Tx'''\n",
    "cur.execute(drop_Table)\n",
    "myconnection.commit()\n",
    "\n",
    "Create_QueryB1='''create table if not exists Map_Tx(States char(255),Years int, Quaters int, Districts char(255),\n",
    "                                            Transaction_count bigint, Transaction_amount bigint)'''\n",
    "cur.execute(Create_QueryB1)\n",
    "myconnection.commit()\n",
    "\n",
    "Insert_QueryB1='''insert into Map_Tx(States, Years, Quaters, Districts, Transaction_count, Transaction_amount)\n",
    "                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "Map_Tx_datas= Map_Tx_df.values.tolist()\n",
    "\n",
    "cur.executemany(Insert_QueryB1,Map_Tx_datas)\n",
    "myconnection.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b19a9ab",
   "metadata": {},
   "source": [
    "USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql connection\n",
    "myconnection = pymysql.connect(host = '127.0.0.1',user='root',passwd='root',database = \"phonepe\",port=3306)\n",
    "cur = myconnection.cursor()\n",
    "\n",
    "#Map_User_query\n",
    "drop_Table='''drop table if exists Map_User'''\n",
    "cur.execute(drop_Table)\n",
    "myconnection.commit()\n",
    "\n",
    "Create_QueryB2='''create table if not exists Map_User(States char(255),Years int, Quaters int, Districts char(255),\n",
    "                                            Registered_Users bigint, App_Opens bigint)'''\n",
    "cur.execute(Create_QueryB2)\n",
    "myconnection.commit()\n",
    "\n",
    "Insert_QueryB2='''insert into Map_User(States, Years, Quaters, Districts, Registered_Users, App_Opens)\n",
    "                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "Map_Us_datas= Map_Us_df.values.tolist()\n",
    "\n",
    "cur.executemany(Insert_QueryB2,Map_Us_datas)\n",
    "myconnection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570525bd",
   "metadata": {},
   "source": [
    "INSURANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql connection\n",
    "myconnection = pymysql.connect(host = '127.0.0.1',user='root',passwd='root',database = \"phonepe\",port=3306)\n",
    "cur = myconnection.cursor()\n",
    "\n",
    "#Map_Ins_query\n",
    "drop_Table='''drop table if exists Map_Ins'''\n",
    "cur.execute(drop_Table)\n",
    "myconnection.commit()\n",
    "\n",
    "Create_QueryB3='''create table if not exists Map_Ins(States char(255),Years int, Quaters int, Districts char(255),\n",
    "                                            Transaction_count bigint, Transaction_amount bigint)'''\n",
    "cur.execute(Create_QueryB3)\n",
    "myconnection.commit()\n",
    "\n",
    "Insert_QueryB3='''insert into Map_Ins(States, Years, Quaters, Districts, Transaction_count, Transaction_amount)\n",
    "                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "Map_Ins_datas= Map_ins_df.values.tolist()\n",
    "\n",
    "cur.executemany(Insert_QueryB3,Map_Ins_datas)\n",
    "myconnection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d424f0ce",
   "metadata": {},
   "source": [
    "\n",
    "TABLE CREATION FOR TOP DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebdfaa",
   "metadata": {},
   "source": [
    "TRANSACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd455ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql connection\n",
    "myconnection = pymysql.connect(host = '127.0.0.1',user='root',passwd='root',database = \"phonepe\",port=3306)\n",
    "cur = myconnection.cursor()\n",
    "\n",
    "#Top_trans_query\n",
    "drop_Table='''drop table if exists Top_Tx'''\n",
    "cur.execute(drop_Table)\n",
    "myconnection.commit()\n",
    "\n",
    "Create_QueryC1='''create table if not exists Top_Tx(States char(255),Years int, Quaters int, Pincodes int,\n",
    "                                            Transaction_count bigint, Transaction_amount bigint)'''\n",
    "cur.execute(Create_QueryC1)\n",
    "myconnection.commit()\n",
    "\n",
    "Insert_QueryC1='''insert into Top_Tx(States, Years, Quaters, Pincodes, Transaction_count, Transaction_amount)\n",
    "                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "Top_Tx_datas= Top_Tx_df.values.tolist()\n",
    "\n",
    "cur.executemany(Insert_QueryC1,Top_Tx_datas)\n",
    "myconnection.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a695a",
   "metadata": {},
   "source": [
    "USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76378f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql connection\n",
    "myconnection = pymysql.connect(host = '127.0.0.1',user='root',passwd='root',database = \"phonepe\",port=3306)\n",
    "cur = myconnection.cursor()\n",
    "\n",
    "#Top_User_query\n",
    "drop_Table='''drop table if exists Top_User'''\n",
    "cur.execute(drop_Table)\n",
    "myconnection.commit()\n",
    "\n",
    "\n",
    "Create_QueryC2='''create table if not exists Top_User(States char(255),Years int, Quaters int, Pincodes int,\n",
    "                                            Registered_Users bigint)'''\n",
    "cur.execute(Create_QueryC2)\n",
    "myconnection.commit()\n",
    "\n",
    "Insert_QueryC2='''insert into Top_User(States, Years, Quaters, Pincodes, Registered_Users)\n",
    "                        values(%s,%s,%s,%s,%s)'''\n",
    "\n",
    "Top_Us_datas= Top_Us_df.values.tolist()\n",
    "\n",
    "cur.executemany(Insert_QueryC2,Top_Us_datas)\n",
    "myconnection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0399f654",
   "metadata": {},
   "source": [
    "INSURANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea630c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql connection\n",
    "myconnection = pymysql.connect(host = '127.0.0.1',user='root',passwd='root',database = \"phonepe\",port=3306)\n",
    "cur = myconnection.cursor()\n",
    "\n",
    "#Top_Ins_query\n",
    "drop_Table='''drop table if exists Top_Ins'''\n",
    "cur.execute(drop_Table)\n",
    "myconnection.commit()\n",
    "\n",
    "Create_QueryC3='''create table if not exists Top_Ins(States char(255),Years int, Quaters int, Pincodes int,\n",
    "                                            Transaction_count bigint, Transaction_amount bigint)'''\n",
    "cur.execute(Create_QueryC3)\n",
    "myconnection.commit()\n",
    "\n",
    "Insert_QueryC3='''insert into Top_Ins(States, Years, Quaters, Pincodes, Transaction_count, Transaction_amount)\n",
    "                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "Top_Ins_datas= Top_ins_df.values.tolist()\n",
    "\n",
    "cur.executemany(Insert_QueryC3,Top_Ins_datas)\n",
    "myconnection.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
